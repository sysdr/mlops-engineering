#!/bin/bash

# Exit immediately if a command exits with a non-zero status.
set -e

echo "ðŸš€ Starting MLOps Day 1 Project Setup and Demo..."

PROJECT_DIR="mlops-day1"
MODEL_ARTIFACT_DIR="$PROJECT_DIR/model_artifact"
MODEL_SERVICE_DIR="$PROJECT_DIR/model_service"
VENV_DIR="$PROJECT_DIR/venv"
DOCKER_IMAGE_NAME="mlops-day1-model-service"
DOCKER_CONTAINER_NAME="mlops-day1-model-container"
API_PORT=5000
TRAIN_SCRIPT="train_model.py"
INFERENCE_CODE="inference_code.py"
APP_SCRIPT="app.py"

# --- 1. Create Project & File Structure ---
echo "1. Creating project directory structure..."
mkdir -p "$MODEL_ARTIFACT_DIR"
mkdir -p "$MODEL_SERVICE_DIR"

# --- 2. Generate Source Code ---

# model_artifact/train_model.py
echo "2a. Generating model training script ($MODEL_ARTIFACT_DIR/$TRAIN_SCRIPT)..."
cat << EOF > "$MODEL_ARTIFACT_DIR/$TRAIN_SCRIPT"
import joblib
from sklearn.datasets import load_iris
from sklearn.linear_model import LogisticRegression
import os

print("Training a simple Logistic Regression model on Iris dataset...")
X, y = load_iris(return_X_y=True)
model = LogisticRegression(solver='liblinear', multi_class='ovr', max_iter=1000)
model.fit(X, y)

model_path = os.path.join(os.path.dirname(__file__), "model.pkl")
joblib.dump(model, model_path)
print(f"Model trained and saved to {model_path}")
EOF

# model_artifact/inference_code.py
echo "2b. Generating model inference code ($MODEL_ARTIFACT_DIR/$INFERENCE_CODE)..."
cat << EOF > "$MODEL_ARTIFACT_DIR/$INFERENCE_CODE"
import joblib
import os
import numpy as np

MODEL_PATH = os.path.join(os.path.dirname(__file__), "model.pkl")
_model = None

def load_model():
    global _model
    if _model is None:
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"Model file not found at {MODEL_PATH}. Please ensure model.pkl is present.")
        print(f"Loading model from {MODEL_PATH}...")
        _model = joblib.load(MODEL_PATH)
        print("Model loaded successfully.")
    return _model

def predict(data_point):
    model = load_model()
    # Ensure data_point is a 2D array, even for a single sample
    if isinstance(data_point, list):
        data_point = np.array(data_point).reshape(1, -1)
    elif not isinstance(data_point, np.ndarray):
        raise TypeError("Input data must be a list or numpy array.")
    
    if data_point.ndim == 1: # Convert 1D array to 2D for single sample prediction
        data_point = data_point.reshape(1, -1)
    
    prediction = model.predict(data_point)
    return prediction.tolist()

if __name__ == "__main__":
    # Simple test
    load_model()
    sample_input = [5.1, 3.5, 1.4, 0.2] # Sample from Iris dataset
    print(f"Sample input: {sample_input}")
    prediction = predict(sample_input)
    print(f"Prediction for sample input: {prediction}")
EOF

# model_artifact/requirements.txt
echo "2c. Generating model_artifact requirements file ($MODEL_ARTIFACT_DIR/requirements.txt)..."
# Using known compatible versions for demonstration
cat << EOF > "$MODEL_ARTIFACT_DIR/requirements.txt"
scikit-learn==1.3.0
joblib==1.3.2
numpy==1.26.2
EOF

# model_service/app.py
echo "2d. Generating API service script ($MODEL_SERVICE_DIR/$APP_SCRIPT)..."
cat << EOF > "$MODEL_SERVICE_DIR/$APP_SCRIPT"
from flask import Flask, request, jsonify
import sys
import os

# Add model_artifact directory to Python path to import inference_code
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../model_artifact')))

try:
    from inference_code import predict, load_model
except ImportError as e:
    print(f"Error importing inference_code: {e}. Make sure model_artifact directory is correctly structured.")
    sys.exit(1)

app = Flask(__name__)

# Metrics for dashboard (updated by requests)
METRICS = {"predictions_total": 0, "health_checks_total": 0, "requests_total": 0}

# Load model once when the application starts
try:
    load_model()
except FileNotFoundError as e:
    print(f"CRITICAL ERROR: {e}")
    print("Please ensure the model.pkl file is generated by running train_model.py.")
    sys.exit(1)
except Exception as e:
    print(f"CRITICAL ERROR loading model: {e}")
    sys.exit(1)

@app.route('/predict', methods=['POST'])
def predict_endpoint():
    METRICS["requests_total"] += 1
    if not request.is_json:
        return jsonify({"error": "Request must be JSON"}), 400
    
    data = request.get_json()
    features = data.get("features")

    if not features or not isinstance(features, list):
        return jsonify({"error": "Invalid input: 'features' must be a list"}), 400
    
    try:
        prediction = predict(features)
        METRICS["predictions_total"] += 1
        return jsonify({"prediction": prediction}), 200
    except Exception as e:
        app.logger.error(f"Prediction error: {e}")
        return jsonify({"error": str(e)}), 500

@app.route('/health', methods=['GET'])
def health_check():
    METRICS["health_checks_total"] += 1
    METRICS["requests_total"] += 1
    return jsonify({"status": "healthy"}), 200

@app.route('/metrics', methods=['GET'])
def metrics():
    return jsonify(METRICS), 200, {'Cache-Control': 'no-store, no-cache, must-revalidate', 'Pragma': 'no-cache'}

@app.route('/dashboard')
def dashboard():
    html = '''<!DOCTYPE html>
<html><head><title>MLOps Day1 Dashboard</title>
<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
<meta http-equiv="Pragma" content="no-cache">
<style>body{font-family:sans-serif;margin:2rem;background:#1a1a2e;color:#eee;}
h1{color:#0f3460;} .metric{background:#16213e;padding:1rem;margin:0.5rem 0;border-radius:8px;display:inline-block;min-width:140px;}
.metric span{font-size:1.5rem;color:#e94560;} #updated{font-size:0.9rem;color:#888;margin-top:1rem;}
button{background:#e94560;color:#fff;border:none;padding:0.5rem 1rem;border-radius:6px;cursor:pointer;font-size:1rem;}
button:hover:not(:disabled){background:#ff6b6b;} button:disabled{opacity:0.6;cursor:not-allowed;}</style></head>
<body><h1>MLOps Day1 Metrics Dashboard</h1>
<div id="metrics">Loading...</div>
<div id="updated"></div>
<p style="margin-top:1.5rem;">
  <button id="triggerBtn" onclick="triggerDemo()">Run demo (call /health + /predict)</button>
  <span id="triggerStatus" style="margin-left:0.5rem;color:#888;"></span>
</p>
<script>
function refresh(){ fetch('/metrics?t='+Date.now()).then(r=>r.json()).then(d=>{
  document.getElementById('metrics').innerHTML =
    '<div class="metric">Predictions total: <span>'+d.predictions_total+'</span></div>'+
    '<div class="metric">Health checks total: <span>'+d.health_checks_total+'</span></div>'+
    '<div class="metric">Requests total: <span>'+d.requests_total+'</span></div>';
  document.getElementById('updated').textContent = 'Last updated: ' + new Date().toLocaleTimeString();
}).catch(function(e){ document.getElementById('metrics').innerHTML='Error loading metrics'; document.getElementById('updated').textContent=''; }); }
function triggerDemo(){
  var btn=document.getElementById('triggerBtn'); var st=document.getElementById('triggerStatus');
  btn.disabled=true; st.textContent='Calling...';
  fetch('/health?t='+Date.now()).then(function(){ return fetch('/predict?t='+Date.now(), { method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify({features:[5.1,3.5,1.4,0.2]}) }); }).then(function(r){ return r.json(); }).then(function(){
    st.textContent='Done. Metrics updated.'; btn.disabled=false; setTimeout(function(){ st.textContent=''; }, 2000);
  }).catch(function(e){ st.textContent='Error: '+e; btn.disabled=false; });
}
refresh(); setInterval(refresh, 1000);
</script></body></html>'''
    return html, 200, {'Content-Type': 'text/html', 'Cache-Control': 'no-store, no-cache, must-revalidate', 'Pragma': 'no-cache'}

if __name__ == '__main__':
    # Flask app runs on 0.0.0.0 for Docker compatibility
    app.run(host='0.0.0.0', port=$API_PORT)
EOF

# model_service/Dockerfile (build from PROJECT_DIR with: docker build -f model_service/Dockerfile .)
echo "2e. Generating Dockerfile ($MODEL_SERVICE_DIR/Dockerfile)..."
cat << EOF > "$MODEL_SERVICE_DIR/Dockerfile"
# Use an official Python runtime as a parent image
FROM python:3.9-slim-buster

# Set the working directory in the container
WORKDIR /app

# Copy model artifact and service code (build context is PROJECT_DIR)
COPY model_artifact /app/model_artifact
COPY model_service/app.py /app/model_service/app.py

# Install deps and train model inside image (so no local Python/pip required)
RUN pip install --no-cache-dir -r model_artifact/requirements.txt && \\
    python model_artifact/train_model.py
RUN pip install --no-cache-dir flask gunicorn

# Make port 5000 available to the world outside this container
EXPOSE 5000

# Run the app using Gunicorn for production-grade deployment
# Single worker so in-memory METRICS update in real time for dashboard
CMD ["gunicorn", "--bind", "0.0.0.0:5000", "--workers", "1", "model_service.app:app"]
EOF

# Startup script: start API (local gunicorn from PROJECT_DIR)
echo "2f. Generating startup script ($PROJECT_DIR/start.sh)..."
cat << 'STARTEOF' > "$PROJECT_DIR/start.sh"
#!/bin/bash
set -e
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"
if pgrep -f "gunicorn.*model_service.app" >/dev/null; then echo "Service already running."; exit 0; fi
if lsof -i :5000 >/dev/null 2>&1 || (command -v python3 >/dev/null && python3 -c "import socket; s=socket.socket(); s.settimeout(1); s.connect(('127.0.0.1',5000)); s.close()" 2>/dev/null); then echo "Port 5000 in use. Stop other service (e.g. stop.sh or docker stop mlops-day1-model-container) first."; exit 1; fi
command -v gunicorn >/dev/null || { echo "gunicorn not found. Run setup.sh with venv/pip or use Docker."; exit 1; }
[ -f "venv/bin/activate" ] && source venv/bin/activate
gunicorn --bind "127.0.0.1:5000" --workers 1 model_service.app:app &
echo "API started at http://127.0.0.1:5000 (PID $!)"
STARTEOF
chmod +x "$PROJECT_DIR/start.sh"

# Stop script: stop local gunicorn and Docker container
echo "2g. Generating stop script ($PROJECT_DIR/stop.sh)..."
cat << 'STOPEOF' > "$PROJECT_DIR/stop.sh"
#!/bin/bash
pkill -f "gunicorn.*model_service.app" 2>/dev/null || true
docker stop mlops-day1-model-container 2>/dev/null || true
docker rm mlops-day1-model-container 2>/dev/null || true
echo "Stopped local API and Docker container."
STOPEOF
chmod +x "$PROJECT_DIR/stop.sh"

# Test script: verify /health, /predict, /metrics
echo "2h. Generating test script ($PROJECT_DIR/run_tests.sh)..."
cat << 'TESTEOF' > "$PROJECT_DIR/run_tests.sh"
#!/bin/bash
set -e
API="${API_URL:-http://127.0.0.1:5000}"
echo "Testing API at $API"
echo "1. Health..."
curl -sf "$API/health" | grep -q healthy && echo "   OK" || { echo "   FAIL"; exit 1; }
echo "2. Predict..."
curl -sf -X POST -H "Content-Type: application/json" -d '{"features":[5.1,3.5,1.4,0.2]}' "$API/predict" | grep -q prediction && echo "   OK" || { echo "   FAIL"; exit 1; }
echo "3. Metrics..."
curl -sf "$API/metrics" | grep -q predictions_total && echo "   OK" || { echo "   FAIL"; exit 1; }
echo "All tests passed."
TESTEOF
chmod +x "$PROJECT_DIR/run_tests.sh"

echo "All source files generated."

# --- 3. Install Dependencies and Train (optional; skip if no pip) ---
USE_VENV=
DID_LOCAL_TRAIN=
if python3 -m venv "$VENV_DIR" 2>/dev/null; then
  source "$VENV_DIR/bin/activate"
  pip install -q flask gunicorn
  pip install -q -r "$MODEL_ARTIFACT_DIR/requirements.txt"
  USE_VENV=1
  echo "3. Dependencies installed in virtual environment."
  echo "4. Training the model and creating model.pkl..."
  python "$MODEL_ARTIFACT_DIR/$TRAIN_SCRIPT"
  DID_LOCAL_TRAIN=1
elif python3 -m pip --version >/dev/null 2>&1; then
  echo "3. Using python3 -m pip (no venv)..."
  python3 -m pip install -q --user flask gunicorn
  python3 -m pip install -q --user -r "$MODEL_ARTIFACT_DIR/requirements.txt"
  echo "4. Training the model and creating model.pkl..."
  python "$MODEL_ARTIFACT_DIR/$TRAIN_SCRIPT"
  DID_LOCAL_TRAIN=1
else
  echo "3. Skipping local install (no venv/pip). Model will be trained inside Docker build."
fi

# --- 5. Run API locally and demo (only if local stack available) ---
if [ -n "$DID_LOCAL_TRAIN" ]; then
  echo "5. Launching API service locally..."
  (cd "$PROJECT_DIR" && gunicorn --bind "127.0.0.1:$API_PORT" --workers 1 model_service.app:app) &
  GUNICORN_PID=$!
  echo "Waiting for API to start (5 seconds)..."
  sleep 5
  echo "6. Testing locally (updating dashboard metrics)..."
  curl -s -o /dev/null "http://127.0.0.1:$API_PORT/health" || true
  curl_output=$(curl -s -X POST \
    -H "Content-Type: application/json" \
    -d '{"features": [5.1, 3.5, 1.4, 0.2]}' \
    "http://127.0.0.1:$API_PORT/predict")
  echo "Local API response: $curl_output"
  if ! echo "$curl_output" | grep -q "prediction"; then
    echo "âŒ Local API verification failed."
    kill $GUNICORN_PID 2>/dev/null || true
    [ -n "$USE_VENV" ] && deactivate 2>/dev/null || true
    exit 1
  fi
  echo "âœ… Local API verified. Stopping local service..."
  kill $GUNICORN_PID 2>/dev/null || true
  [ -n "$USE_VENV" ] && deactivate 2>/dev/null || true
else
  echo "5. Skipping local API (no local Python)."
fi

# --- 7. Build, Run, Test with Docker ---
echo "7. Building Docker image (from $PROJECT_DIR)..."
docker build -t "$DOCKER_IMAGE_NAME" -f "$MODEL_SERVICE_DIR/Dockerfile" "$PROJECT_DIR"

echo "7b. Running Docker container..."
docker run -d -p "$API_PORT:$API_PORT" --name "$DOCKER_CONTAINER_NAME" "$DOCKER_IMAGE_NAME"
echo "Docker container '$DOCKER_CONTAINER_NAME' running on http://localhost:$API_PORT"
echo "Waiting for Docker API to start (10 seconds)..."
sleep 10

# --- 8. Demo and Verify Functionality (With Docker) ---
echo "8. Testing API functionality via Docker (hitting /health and /predict for dashboard metrics)..."
curl -s -o /dev/null "http://localhost:$API_PORT/health" || true
echo "Sending prediction request to http://localhost:$API_PORT/predict"
docker_curl_output=$(curl -s -X POST \
  -H "Content-Type: application/json" \
  -d '{"features": [5.1, 3.5, 1.4, 0.2]}' \
  "http://localhost:$API_PORT/predict")

echo "Docker API response: $docker_curl_output"

if echo "$docker_curl_output" | grep -q "prediction"; then
  echo "âœ… Docker API functionality verified: Prediction received."
else
  echo "âŒ Docker API functionality verification failed."
  # Clean up Docker container on failure
  docker stop "$DOCKER_CONTAINER_NAME" > /dev/null 2>&1 || true
  docker rm "$DOCKER_CONTAINER_NAME" > /dev/null 2>&1 || true
  exit 1
fi

# --- 9. Verify generated files ---
echo "9. Verifying generated files..."
for f in "$MODEL_ARTIFACT_DIR/$TRAIN_SCRIPT" "$MODEL_ARTIFACT_DIR/$INFERENCE_CODE" "$MODEL_ARTIFACT_DIR/requirements.txt" "$MODEL_SERVICE_DIR/$APP_SCRIPT" "$MODEL_SERVICE_DIR/Dockerfile" "$PROJECT_DIR/start.sh" "$PROJECT_DIR/stop.sh" "$PROJECT_DIR/run_tests.sh"; do
  if [ -f "$f" ]; then echo "  OK $f"; else echo "  MISSING $f"; exit 1; fi
done
if [ -n "$DID_LOCAL_TRAIN" ]; then
  [ -f "$MODEL_ARTIFACT_DIR/model.pkl" ] && echo "  OK $MODEL_ARTIFACT_DIR/model.pkl" || { echo "  MISSING model.pkl"; exit 1; }
fi
echo "  All generated files present."

echo "All setup, demo, and verification steps completed successfully!"
echo "Start API (local): $(pwd)/$PROJECT_DIR/start.sh"
echo "Run tests: $(pwd)/$PROJECT_DIR/run_tests.sh   (use API_URL=http://127.0.0.1:5000 or leave default for Docker on 5000)"
echo "Dashboard: http://localhost:$API_PORT/dashboard"
echo "To stop: $(pwd)/$PROJECT_DIR/stop.sh   or: docker stop $DOCKER_CONTAINER_NAME"